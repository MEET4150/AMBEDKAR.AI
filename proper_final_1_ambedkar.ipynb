{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRLlKq8wOXfwAFyLJ4IdOb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n2Ve7lquiUuk",
        "outputId": "13e2e932-8ee4-4130-cfc9-e0ab650a71cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“š Welcome to Ambedkar 2.1 Ultra Pro - Indian Legal Assistant\n",
            "ğŸ”‘ Enter your plan ID (555 or 1111): 555\n",
            "\n",
            "ğŸ‘¨â€âš–ï¸ Start chatting with Ambedkar AI below.\n",
            "ğŸ“ [upload] to upload document | ğŸŒ [translate] to translate document | ğŸ“° [news] | ğŸšª [exit]\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "You: upload\n",
            "\n",
            "ğŸ§  Ambedkar AI:\n",
            "Okay, I understand. You've said \"upload\". To provide a helpful response, I need more context. Under Indian law, \"upload\" can relate to various legal situations. To give you a relevant interpretation, please clarify:\n",
            "\n",
            "*   **What type of data are you referring to uploading?** (e.g., documents, images, videos, financial information)\n",
            "*   **Where are you uploading it?** (e.g., a website, a social media platform, a government portal, to another individual)\n",
            "*   **Why are you uploading it?** (e.g., as evidence, for a job application, to share information)\n",
            "*   **What is your concern related to the upload?** (e.g., data privacy, copyright infringement, potential liability)\n",
            "\n",
            "Once you provide this information, I can analyze the situation under relevant Indian laws such as:\n",
            "\n",
            "*   **Information Technology Act, 2000:** Deals with electronic records, digital signatures, cybercrime, and intermediary liability. Relevant sections would depend on the specific context.\n",
            "*   **Indian Penal Code, 1860 (IPC):** Could be relevant if the uploaded content is obscene (Section 292), defamatory (Section 499), incites violence (various sections), or is part of a criminal conspiracy.\n",
            "*   **Copyright Act, 1957:** If the content is copyrighted, uploading it without permission could constitute copyright infringement.\n",
            "*   **The IT (Intermediary Guidelines and Digital Media Ethics Code) Rules, 2021:** This governs social media platforms, online news, and streaming services, addressing issues such as content takedown and due diligence.\n",
            "*   **Specific laws related to data protection:** Depending on the nature of the data, laws related to data protection and privacy might apply. (Currently, the Digital Personal Data Protection Act, 2023 is the governing law in this area).\n",
            "\n",
            "Without specific information, I cannot provide accurate or useful legal guidance. Please provide more details about the upload you are referring to.\n",
            "\n",
            "\n",
            "ğŸ”¢ âœ… Token usage: 325/10000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "You: [upload]\n",
            "ğŸ“ Enter full file path: /content/SCA-Ambalal Maganlal Rana (1).docx\n",
            "âœ… Document uploaded. Context is now active.\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "You: provide me the summary of the uploded document \n",
            "\n",
            "ğŸ§  Ambedkar AI:\n",
            "This document outlines the case of Ambalal Maganlal Rana, who was appointed as a Water Bearer on an ad-hoc basis in the Panchmahal district of Godhra in 1986. Over the years, Rana made numerous representations to various authorities within the Gujarat Police Department, seeking regularization of his employment, conversion of his post to a Class-IV Peon position, and absorption into a permanent post. He based his requests on Government of Gujarat circulars dated 26.12.1980 and 15.10.1992, and a Gujarat High Court judgment in SCA/1209/1994. However, his requests were consistently denied, with the final denial in 2003 citing the suspension of the circular dated 21.08.1995. This series of events forms the basis of Special Civil Application No. _________ of 2025 filed in the High Court of Gujarat at Ahmedabad. The petitioner is essentially seeking judicial intervention to address his grievance regarding non-regularization despite prolonged service.\n",
            "\n",
            "\n",
            "ğŸ”¢ âœ… Token usage: 929/10000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "You: provide me the argument and amendment which are refering to this document \n",
            "\n",
            "ğŸ§  Ambedkar AI:\n",
            "Based on the provided document, the petitioner, Ambalal Maganlal Rana, is primarily arguing for the regularization of his ad-hoc appointment as a Water Bearer, later requesting conversion to a Class-IV Peon.\n",
            "\n",
            "Here's a breakdown of the argument and the implied basis for it:\n",
            "\n",
            "**Argument:**\n",
            "\n",
            "*   **Prolonged Service:** The petitioner repeatedly emphasizes his long service period (from 1986 onwards) as a justification for regularization/absorption.\n",
            "*   **Government Circulars:** The petitioner heavily relies on Government of Gujarat circulars dated 26.12.1980 and 15.10.1992, implying these circulars provide a basis for regularizing ad-hoc employees or converting posts.\n",
            "*   **Financial Hardship:** The petitioner cites financial hardship as a reason for his request, likely hoping to evoke sympathetic consideration.\n",
            "*   **Precedent:** The petitioner refers to a Gujarat High Court judgment in SCA/1209/1994 dated 27.07.1998, suggesting it clarifies government circulars relevant to his case.\n",
            "\n",
            "**Implied Legal Basis/Amendment Reference (Though not explicitly stated, these are what the petitioner *likely* believes apply based on his reliance on the circulars):**\n",
            "\n",
            "*   The petitioner's repeated references to the Government of Gujarat circulars (26.12.1980 and 15.10.1992) suggest he believes these circulars contain provisions that mandate or enable the regularization of ad-hoc employees after a certain period, or facilitate the conversion of temporary positions to permanent ones.\n",
            "*   **Suspension of Circular:** The denial letter dated 03.12.2003 mentions the \"suspension of the circular dated 21.08.1995\". This implies that government circulars related to regularization or conversion of posts could be subject to change or suspension by the government.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Specific Content of Circulars:** The key to understanding the petitioner's argument lies in the *specific content* of the Government of Gujarat circulars dated 26.12.1980 and 15.10.1992. The document provided does not include these circulars, so it's impossible to definitively say what legal provisions the petitioner is relying on.\n",
            "*   **Applicability of Circulars:** Even if the circulars exist and contain provisions seemingly favorable to the petitioner, their applicability to his specific case would need to be determined by the court. Factors like the nature of his employment (ad-hoc, part-time), the specific rules governing Water Bearer positions in the police department, and any subsequent government policies would be relevant.\n",
            "*   **Judicial Interpretation:** The reference to the High Court judgment in SCA/1209/1994 suggests the petitioner believes that case provides a favorable interpretation of the relevant government circulars. However, the actual holding and reasoning of that case would need to be examined to determine its relevance to the petitioner's situation.\n",
            "*   **Suspension of Circular (21.08.1995):** The denial letter's mention of the suspension of the 21.08.1995 circular implies that circulars can be suspended or revoked. If the circulars the petitioner relies on have also been suspended or revoked, his claim would be significantly weakened.\n",
            "\n",
            "Without the actual text of the referenced circulars and the cited High Court judgment, it's impossible to provide a precise legal analysis. This response is based solely on the information provided in the \"List of Dates and Events.\"\n",
            "\n",
            "\n",
            "ğŸ”¢ âœ… Token usage: 1875/10000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "You: what acts will be used for us ?\n",
            "\n",
            "ğŸ§  Ambedkar AI:\n",
            "Based on the provided \"List of Dates and Events\" from the Special Civil Application No._________ of 2025, it's difficult to definitively state which specific Acts will be directly invoked without knowing the petitioner's specific grievances and the reliefs sought. However, given the context of employment regularization within the Gujarat State government, the following categories of Indian law and potential specific Acts are likely to be relevant:\n",
            "\n",
            "1.  **Constitutional Law:**\n",
            "    *   **Article 14 of the Constitution of India:** Deals with equality before the law. The petitioner might argue that the denial of regularization, despite prolonged service and reliance on government circulars, violates his right to equality.\n",
            "    *   **Article 16 of the Constitution of India:** Deals with equality of opportunity in matters of public employment. The petitioner could argue that the failure to regularize him constitutes a denial of equal opportunity.\n",
            "    *   **Article 21 of the Constitution of India:** Deals with protection of life and personal liberty. This could be relevant if the petitioner argues that the lack of regularization impacts their livelihood and thus violates their right to life with dignity.\n",
            "\n",
            "2.  **Labour Law/Service Law Principles:**\n",
            "    *   While there is no single \"Service Law Act\" applicable across India, the principles of service law developed through judicial pronouncements will be relevant. These principles govern the terms and conditions of employment of government servants.\n",
            "    *   **The Industrial Disputes Act, 1947:** While less directly applicable to government servants, principles from this Act regarding fairness and natural justice might be invoked.\n",
            "\n",
            "3.  **Specific Government Circulars and Orders:**\n",
            "    *   The document repeatedly mentions Government of Gujarat circulars dated 26.12.1980 and 15.10.1992, and 21.08.1995. The specific content of these circulars will be crucial. If these circulars provided for a path to regularization, the petitioner will rely heavily on them. The State's suspension of the circular dated 21.08.1995 will be a key point of contention.\n",
            "    *   Any other relevant government resolutions (GRs) or orders pertaining to ad-hoc appointments, regularization, or the classification of posts (e.g., Water Bearer vs. Class-IV Peon) within the Gujarat State government will be important.\n",
            "\n",
            "4.  **Judicial Precedents:**\n",
            "    *   The petitioner's representation dated 18.02.2000 mentions reliance on a Gujarat High Court judgment in SCA/1209/1994 dated 27.07.1998. This judgment and other relevant judgments of the Supreme Court and High Courts concerning regularization of ad-hoc employees will be highly relevant.\n",
            "\n",
            "**In Summary:** The case will likely revolve around arguments based on Articles 14, 16, and potentially 21 of the Constitution, principles of service law, the interpretation and applicability of the Gujarat Government circulars, and relevant judicial precedents.\n",
            "\n",
            "\n",
            "ğŸ”¢ âœ… Token usage: 2755/10000\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import docx2txt\n",
        "from googletrans import Translator\n",
        "from google.generativeai import configure, GenerativeModel\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# === Gemini Setup ===\n",
        "configure(api_key=\"AIzaSyBqk4WXN7k4UhjaBCzgSmuWn_bEor5aSyw\")  # Replace with your Gemini key\n",
        "model = GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# === System Instruction ===\n",
        "system_instruction = (\n",
        "    \"You are Ambedkar AI, a legal assistant exclusively trained on the Indian legal system.\\n\"\n",
        "    \"Your task is to interpret laws, judgments, and legal documents strictly according to Indian law.\\n\"\n",
        "    \"Never provide advice based on international laws. Always cite IPC, CrPC, or applicable Indian acts.\\n\"\n",
        ")\n",
        "\n",
        "# === User Token Plans ===\n",
        "USER_TOKENS = {\n",
        "    \"555\": 10000,\n",
        "    \"1111\": 200000,\n",
        "}\n",
        "token_usage = {}\n",
        "\n",
        "def check_token_limit(user_id, tokens_used):\n",
        "    allowed = USER_TOKENS.get(user_id)\n",
        "    if allowed is None:\n",
        "        return False, \"âŒ Invalid plan ID.\"\n",
        "    used = token_usage.get(user_id, 0)\n",
        "    if used + tokens_used > allowed:\n",
        "        return False, f\"âŒ Token limit exceeded: {used + tokens_used}/{allowed}\"\n",
        "    token_usage[user_id] = used + tokens_used\n",
        "    return True, f\"âœ… Token usage: {token_usage[user_id]}/{allowed}\"\n",
        "\n",
        "# === File Reader ===\n",
        "def extract_text(file_path):\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    try:\n",
        "        if ext == \".pdf\":\n",
        "            text = \"\"\n",
        "            with open(file_path, 'rb') as f:\n",
        "                reader = PyPDF2.PdfReader(f)\n",
        "                for page in reader.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\"\n",
        "            return text\n",
        "        elif ext == \".docx\":\n",
        "            return docx2txt.process(file_path)\n",
        "        elif ext == \".txt\":\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                return f.read()\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        return f\"[ERROR] Failed to extract: {e}\"\n",
        "\n",
        "# === Google Translate ===\n",
        "def translate_text(text, target_lang='en'):\n",
        "    try:\n",
        "        if not text:\n",
        "            return \"âš ï¸ No document content to translate.\"\n",
        "        # Ensure text is a string before translation\n",
        "        text_to_translate = str(text)\n",
        "        translator = Translator()\n",
        "        translated = translator.translate(text_to_translate, dest=target_lang)\n",
        "        return translated.text\n",
        "    except Exception as e:\n",
        "        return f\"[ERROR] Translation failed: {e}\"\n",
        "\n",
        "# === Legal News ===\n",
        "def fetch_legal_news():\n",
        "    try:\n",
        "        url = \"https://www.barandbench.com/news\"\n",
        "        r = requests.get(url)\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        headlines = [h.get_text(strip=True) for h in soup.find_all(\"h3\")[:5]]\n",
        "        return \"\\n\".join(headlines) if headlines else \"No headlines found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching news: {e}\"\n",
        "\n",
        "# === Gemini Chat Function ===\n",
        "def chat_gemini(prompt, user_id, doc_context=\"\"):\n",
        "    try:\n",
        "        context_note = f\"\\nRefer to the uploaded document:\\n{doc_context[:3000]}\\n\" if doc_context else \"\"\n",
        "        full_prompt = f\"{system_instruction}{context_note}User Query: {prompt}\"\n",
        "        response = model.generate_content(full_prompt)\n",
        "        tokens_used = len(full_prompt.split()) + len(response.text.split())\n",
        "        status, msg = check_token_limit(user_id, tokens_used)\n",
        "        if not status:\n",
        "            return msg\n",
        "        return f\"\\nğŸ§  Ambedkar AI:\\n{response.text}\\n\\nğŸ”¢ {msg}\"\n",
        "    except Exception as e:\n",
        "        return f\"Gemini Error: {e}\"\n",
        "\n",
        "# === Chat Interface ===\n",
        "def main():\n",
        "    print(\"ğŸ“š Welcome to Ambedkar 2.1 Ultra Pro - Indian Legal Assistant\")\n",
        "    user_id = input(\"ğŸ”‘ Enter your plan ID (555 or 1111): \").strip()\n",
        "\n",
        "    if user_id not in USER_TOKENS:\n",
        "        print(\"âŒ Invalid plan ID.\")\n",
        "        return\n",
        "\n",
        "    doc_context = \"\"\n",
        "    print(\"\\nğŸ‘¨â€âš–ï¸ Start chatting with Ambedkar AI below.\")\n",
        "    print(\"ğŸ“ [upload] to upload document | ğŸŒ [translate] to translate document | ğŸ“° [news] | ğŸšª [exit]\\n\")\n",
        "\n",
        "    while True:\n",
        "        print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "        user_input = input(\"You: \").strip().lower().replace(\"'\", \"\").replace('\"', '')\n",
        "\n",
        "        if user_input == \"exit\":\n",
        "            print(\"ğŸ‘‹ Thank you for using Ambedkar. Stay legally empowered!\")\n",
        "            break\n",
        "\n",
        "        elif user_input == \"[upload]\":\n",
        "            path = input(\"ğŸ“ Enter full file path: \").strip()\n",
        "            if not os.path.exists(path):\n",
        "                print(\"âŒ File not found.\")\n",
        "                continue\n",
        "            extracted = extract_text(path)\n",
        "            if not extracted:\n",
        "                print(\"âŒ Unsupported file or empty.\")\n",
        "            else:\n",
        "                doc_context = extracted\n",
        "                print(\"âœ… Document uploaded. Context is now active.\")\n",
        "\n",
        "        elif user_input == \"[translate]\":\n",
        "            if not doc_context:\n",
        "                print(\"âš ï¸ No document uploaded yet.\")\n",
        "                continue\n",
        "            lang = input(\"ğŸŒ Enter target language code (e.g., en, hi, gu): \").strip()\n",
        "            translated = translate_text(doc_context, lang)\n",
        "            print(f\"\\nğŸ“ Translated Document:\\n{translated}\")\n",
        "\n",
        "        elif user_input == \"[news]\":\n",
        "            print(\"\\nğŸ“° Legal Headlines:\\n\")\n",
        "            print(fetch_legal_news())\n",
        "\n",
        "        else:\n",
        "            response = chat_gemini(user_input, user_id, doc_context)\n",
        "            print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8459f23",
        "outputId": "6322e1a5-62ac-4277-ac0f-58648091d276"
      },
      "source": [
        "%pip install PyPDF2 docx2txt googletrans==4.0.0-rc1 beautifulsoup4 requests"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.7.9)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
            "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=7980e2a5329db144b139575d6e14a9baee0f712e4437e1b741fa75a84241271b\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, docx2txt, chardet, PyPDF2, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: hyperframe\n",
            "    Found existing installation: hyperframe 6.1.0\n",
            "    Uninstalling hyperframe-6.1.0:\n",
            "      Successfully uninstalled hyperframe-6.1.0\n",
            "  Attempting uninstall: hpack\n",
            "    Found existing installation: hpack 4.1.0\n",
            "    Uninstalling hpack-4.1.0:\n",
            "      Successfully uninstalled hpack-4.1.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h2\n",
            "    Found existing installation: h2 4.2.0\n",
            "    Uninstalling h2-4.2.0:\n",
            "      Successfully uninstalled h2-4.2.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.24.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio-client 1.10.1 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "langsmith 0.4.4 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio 5.31.0 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.93.3 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 chardet-3.0.4 docx2txt-0.9 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    }
  ]
}